{"config":{"lang":["en","zh"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Balancing","text":"<p>Welcome to Balancing</p>"},{"location":"readme/","title":"Balancing","text":"<p>Currently, Balancing is in the development and testing phase and is not suitable for production environments.</p>"},{"location":"readme/#introduction-to-balancing","title":"Introduction to Balancing","text":"<p>Balancing is a layer 4 load balancing component implemented with eBPF on the Kubernetes platform. It references the functionalities of projects like cilium, calico, and KPNG. Balancing supports running in a containerized manner within a Kubernetes cluster and also supports running in binary form on bare metal, providing CNI-independent load balancing access capabilities for applications inside and outside the Kubernetes cluster.</p>"},{"location":"readme/#current-features","title":"Current Features","text":"<ol> <li> <p>CNI-independent cluster service resolution</p> <ul> <li>Implements service resolution initiated by Pods and Nodes on cluster nodes based on cGroup eBPF, achieving kube-proxy replacement.</li> <li>Implements client-side load balancing resolution on external bare metal and virtual machines to support access to services within the Kubernetes cluster.</li> <li>Future versions will support north-south nodePort resolution on node network cards based on TC eBPF.</li> <li>For more information, please refer to service resolution</li> </ul> </li> <li> <p>Local redirection layer 4 load balancing resolution:</p> <ul> <li>Provides service redirection resolution initiated by Pods and Nodes based on cGroup eBPF to services on the same node, typical scenarios include local coreDns.</li> <li>For more information, please refer to LocalRedirect Policy</li> </ul> </li> <li> <p>Global and external service layer 4 load balancing resolution:</p> <ul> <li>Supports more flexible policy definitions, providing global load balancing strategies for applications inside and outside the cluster.</li> <li>Application scenarios include client-side load balancing resolution for external hosts and load balancing within Kubernetes clusters.</li> <li>For more information, please refer to Balancing Policy</li> </ul> </li> <li> <p>Event logging for resolution metrics:</p> <ul> <li>Records load balancing resolution events and associates related container information to form complete load balancing resolution metrics.</li> </ul> </li> </ol>"},{"location":"readme/#typical-use-cases","title":"Typical Use Cases","text":"<ol> <li> <p>Replacing kube-proxy service resolution in CNI-independent clusters:</p> <ul> <li>Suitable for underlay CNI that cannot implement service, such as Macvlan, SR-IOV CNI, etc.</li> <li>Suitable for CNIs that do not implement eBPF functionality, such as Antrea, Kube-ovn, Flannel, and public cloud clusters.</li> </ul> </li> <li> <p>Service access redirection to local proxies:</p> <ul> <li>Implements high-availability redirection, directing coreDns services to Node-local DNS.</li> <li>Implements node api-server proxy for clusterpedia.</li> </ul> </li> <li> <p>Implementing eBPF layer 4 load balancing on the client side of external applications to access services in Kubernetes clusters:</p> <ul> <li>Applications in bare metal, virtual machines.</li> <li>Applications in kubevirt virtual machines.</li> <li>Edge nodes in kubeedge accessing cloud services (in progress).</li> </ul> </li> <li> <p>Layer 4 load balancing access between multiple clusters:</p> <ul> <li>Cross-cluster service access (in progress).</li> </ul> </li> <li> <p>Providing high-availability load balancing access entry for external bare metal services:</p> <ul> <li>Provides cluster internal load balancing access addresses for external applications through custom load balancing strategies and implements health checks (in progress).</li> </ul> </li> </ol>"},{"location":"readme/#architecture","title":"Architecture","text":"<p>The Balancing component consists of an agent and a controller: - controller deployment: Performs webhook validation and modification of various CRD objects. - agent daemonset: Loads eBPF programs and distributes forwarding rules.</p> <p></p>"},{"location":"readme/#quick-start","title":"Quick Start","text":"<ul> <li>Refer to Installation for quick deployment.</li> <li>Refer to Service Resolution for usage experience.</li> <li>Refer to LocalRedirect Policy for usage experience.</li> <li>Refer to Balancing Policy for usage experience.</li> </ul>"},{"location":"readme/#roadmap","title":"Roadmap","text":"<ul> <li>IP Family and Protocol</li> <li> Support TCP and UDP</li> <li> Support IPv4</li> <li> <p> Support IPv6</p> </li> <li> <p>Observability</p> </li> <li> Load balancing resolution logs</li> <li> <p> Load balancing resolution metrics</p> </li> <li> <p>Service Resolution</p> </li> <li> East-west service resolution</li> <li> North-south service resolution</li> <li> <p> sessionAffinity forwarding record health status</p> </li> <li> <p>LocalRedirect Policy</p> </li> <li> Front supports pointing to service and custom VIP</li> <li> <p> Backend supports pod label selectors</p> </li> <li> <p>Balancing Policy</p> </li> <li> Front supports pointing to service and custom VIP</li> <li> Backend supports pod label selectors</li> <li> Backend supports custom IP and port</li> <li> <p> Inter-node forwarding tunnel</p> </li> <li> <p>Multi-cluster Interconnection</p> </li> <li> Cross-cluster service interconnection</li> <li> <p> Cross-cluster balancing policy</p> </li> <li> <p>Others</p> </li> <li> Support amd architecture</li> <li> Support arm architecture</li> </ul>"},{"location":"readme/#license","title":"License","text":"<p>Balancing follows the Apache License, Version 2.0. For details, see LICENSE.</p>"},{"location":"develop/develop/","title":"Setting Up Development Environment","text":""},{"location":"develop/develop/#host-software-preparation","title":"Host Software Preparation","text":"<ul> <li>Vagrant and VirtualBox</li> <li>helm</li> <li>kubectl</li> <li>jq</li> </ul>"},{"location":"develop/develop/#setting-up-local-development-environment-with-vagrant-vm","title":"Setting Up Local Development Environment with Vagrant VM","text":"<ol> <li> <p>Build the balancing image</p> <pre><code>make build_local_image\n\n# For users in China, you can use a proxy source to speed up the build\nmake build_local_image -e USE_PROXY_SOURCE=true\n</code></pre> </li> <li> <p>Build the test application image</p> <pre><code>make build_local_test_app_image\n</code></pre> </li> <li> <p>Deploy a dual-node Kubernetes cluster based on VMs (without installing the kube-proxy component)</p> <pre><code>make e2e_init -e E2E_SKIP_KUBE_PROXY=true -e E2E_INSTALL_PYROSCOPE=false\n</code></pre> </li> <li> <p>Deploy balancing and test applications to the cluster</p> <pre><code>make e2e_deploy -e E2E_REDIRECT_QOS_LIMIT=1\n\n# Or use specified image tags\nmake e2e_deploy -e PROJECT_IMAGE_TAG=8877a79da7c0a9f159363660b5b23e5458480aea \\\n                -e TEST_APP_IMAGE_TAG=aa7693a44e205c13e9bd3bee63260c9c1048ce24\n</code></pre> </li> <li> <p>Test various strategies of balancing</p> <pre><code>make e2e_test_connectivity\n</code></pre> </li> <li> <p>Access <code>http://NodeIP:28000</code> in a browser to observe Golang sampling data in the Proscope Server.</p> </li> </ol>"},{"location":"develop/develop/#debugging-ebpf-on-local-machine","title":"Debugging eBPF on Local Machine","text":"<pre><code>apt-get install clang llvm gcc-multilib libbpf-dev linux-headers-$(uname -r)\n\ncd pkg/ebpf/bpf\n\n# Check for syntax errors\nclang -fsyntax-only -I.  cgroup.c\n</code></pre>"},{"location":"develop/ebpfDebug/","title":"eBPF Debugging","text":"<p>After deploying Balancing, you can check the following to ensure that Balancing is working as expected.</p>"},{"location":"develop/ebpfDebug/#node-ebpf-check","title":"Node eBPF Check","text":"<pre><code># The eBPF map is mounted in the following directory on the host\nls /sys/fs/bpf/balancing/\n# Example output\nmap_affinity  map_backend  map_configure  map_event  map_nat_record  map_node_ip  map_node_proxy_ip  map_service\n\n# Use the following command to query the balancing eBPF map\nbpftool map\n\n# The cgroup v2 is mounted in the following directory on the host\nls /sys/fs/cgroup\n# Example output\ncgroup.controllers  cgroup.stat  cpuset.cpus.isolated  dev-mqueue.mount  io.prio.class  memory.reclaim  proc-sys-fs-binfmt_misc.mount  system.slice\n\n# Use the following command to query the eBPF Program loaded by balancing\nbpftool prog\n\n# Use the following command to query the association of the eBPF Program with cgroup v2 by balancing\nbpftool cgroup tree /run/balancing/cgroupv2\n\n# View the logs printed by the eBPF program on the host\nbpftool prog tracelog\n# or\ncat /sys/kernel/debug/tracing/trace_pipe\n</code></pre>"},{"location":"develop/ebpfDebug/#confirm-balancing-agent-logs","title":"Confirm Balancing Agent Logs","text":"<pre><code># Query the load balancing parsing event logs of the agent pod\nkubectl logs -n elf balancing-agent-q727g | grep \"formatted ebpf event\" | jq .\n</code></pre>"},{"location":"develop/ebpfDebug/#objects","title":"Objects","text":"<pre><code># Confirm that each node is marked with a unique annotation ID\nkubectl get nodes -o jsonpath='{.items[*].metadata.annotations}' | jq .\n# Example output\n{\n  \"balancing.elf.io/nodeId\": \"596592060\",\n  \"balancing.elf.io/nodeProxyIpv4\": \"192.168.0.10\",\n  ...\n}\n</code></pre> <pre><code># All balancingpolicies have a unique id\nkubectl get balancingpolicies -o jsonpath='{.items[*].metadata.annotations}' | jq .\n# Example output\n{\n  \"balancing.elf.io/serviceId\": \"20003\",\n  ...\n}\n</code></pre> <pre><code># All localredirectpolicies have a unique id\nkubectl get localredirectpolicies -o jsonpath='{.items[*].metadata.annotations}' | jq .\n# Example output\n{\n  \"balancing.elf.io/serviceId\": \"10091\",\n  ...\n}\n</code></pre>"},{"location":"develop/ebpfDebug/#view-data-in-ebpf","title":"View Data in eBPF","text":"<p>Enter the agent pod, and use the inspect command to view data in the eBPF map.</p> <pre><code># Query all data in the ebpf map\ninspect showMapData all\n\n# Trace ebpf map data related to a specific service\ninspect traceMapData service $namespace $serviceName\n\n# Trace ebpf map data related to a specific localredirectpolicies\ninspect traceMapData localRedirect $namespace $policyName\n\n# Trace ebpf map data related to a specific balancingpolicies\ninspect traceMapData balancing $namespace $serviceName\n</code></pre>"},{"location":"usages/balancing/","title":"Balancing Policy","text":""},{"location":"usages/balancing/#introduction","title":"Introduction","text":"<p>The Balancing Policy provides a new load balancing mode that complements Kubernetes services, achieving global layer 4 load balancing across the cluster.</p> <p>It supports request redirection for the following objects: * Applications within Pods * Applications on cluster nodes * Applications on external hosts</p>"},{"location":"usages/balancing/#features","title":"Features","text":"<p>Current features include: * [x] Customizable front address for load balancing, which can be a Kubernetes service name or a custom VIP and port. * [x] Customizable backend address for load balancing, specified by pod label selector, supporting the following three methods:     * endpoint IP: The load balancing address is DNAT resolved to the pod IP, applicable for traditional host applications within the cluster accessing a VIP address.     * HostPort: The load balancing address is DNAT resolved to the node IP where the pod resides and the pod's HostPort, applicable for external applications accessing services with defined hostPort within the cluster.     * nodeProxy: The load balancing address is DNAT resolved to the node's Proxy IP and the port defined in the policy, applicable for external applications accessing PODs within the cluster, where the entry address is a public cloud Loadbalancer or nodeport implemented by kube-proxy. The node's Proxy IP is defined in the node object's annotation <code>\"balancing.elf.io/nodeProxyIpv4\": \"192.168.0.10\"</code>, which can be generated by:         * The Balancing agent automatically establishing a tunnel interface on the node and updating it to the node's annotation, suitable for multi-cluster or external host applications.         * Administrators manually setting the annotation <code>\"balancing.elf.io/nodeProxyIpv4\"</code> on the Node object, such as proxy mapping IP or public mapping IP.</p> <p>Note: The front of Balancing Policy and LocalRedirect Policy instances does not support binding the same service or defining the same virtual address, as this will cause resolution conflicts.</p> <p>If the front of Balancing Policy or LocalRedirect Policy uses a custom IP address that conflicts with a Kubernetes service ClusterIP, it will be resolved according to the rules of Balancing Policy or LocalRedirect Policy.</p> <p>Future versions will address the following issues: * [ ] Balancing Agent will support automatically establishing forwarding tunnels between nodes and updating IP addresses to the node's annotation <code>\"balancing.elf.io/nodeProxyIpv4\"</code>, to achieve communication with external hosts and multi-cluster in overlay CNI scenarios. * [ ] Balancing Agent will implement health checks for custom backend IP addresses.</p>"},{"location":"usages/balancing/#use-cases","title":"Use Cases","text":"<ol> <li>Running the balancing agent binary or docker service on external hosts, kubevirt virtual machines, or kubedge edge nodes to access services within the Kubernetes cluster.</li> </ol> <p>Traditional nodePort or Loadbalancer load balancing may encounter SNAT source port conflicts, long connection timeouts, and other issues, becoming bottlenecks for high concurrency access. The new balancing solution enables client-side load balancing resolution, reducing forwarding paths and lowering troubleshooting difficulty.</p> <pre><code>&gt; In the current version, Balancing has not yet completed tunnel establishment and port allocation between nodes, so it can only ensure connectivity within and outside the cluster in underlay CNI scenarios. In future versions, once Balancing completes tunnel establishment, it will ensure connectivity within and outside the cluster in overlay CNI scenarios.\n</code></pre> <ol> <li>Achieving layer 4 load balancing access between multiple clusters.</li> </ol> <p>In the current version, Balancing has not yet completed tunnel establishment and port allocation between nodes, so it can only ensure connectivity within and outside the cluster in underlay CNI scenarios. In future versions, once Balancing completes tunnel establishment, it will ensure connectivity within and outside the cluster in overlay CNI scenarios.</p> <ol> <li> <p>Defining external service load balancing addresses within the cluster to provide high availability and load balancing access to external services.</p> </li> <li> <p>Customizing front load balancing addresses or backend forwarding addresses to support more flexible load balancing needs.</p> </li> </ol>"},{"location":"usages/balancing/#policy-examples","title":"Policy Examples","text":"<p>In the following example, the front specifies a service in Kubernetes, and the backend forwards to the Pod IP based on the pod's label selector.</p> <pre><code>apiVersion: balancing.elf.io/v1beta1\nkind: BalancingPolicy\nmetadata:\n  name: test-service-podendpoint\nspec:\n  frontend:\n    serviceMatcher:\n      serviceName: http-server-balancing-pod-v4\n      namespace: default\n      toPorts:\n        - port: \"8080\"\n          protocol: TCP\n          name: p1\n        - port: \"80\"\n          protocol: TCP\n          name: p2\n  backend:\n    serviceEndpoint:\n      endpointSelector:\n        matchLabels:\n          app: http-redirect\n      redirectMode: podEndpoint\n      toPorts:\n        - port: \"80\"\n          protocol: TCP\n          name: p1\n        - port: \"80\"\n          protocol: TCP\n          name: p2\n</code></pre> <p>In the following example, the front specifies a service in Kubernetes, and the backend forwards to the HostPort of the node where the Pod resides based on the pod's label selector.</p> <pre><code>apiVersion: balancing.elf.io/v1beta1\nkind: BalancingPolicy\nmetadata:\n  name: test-service-hostport\nspec:\n  frontend:\n    serviceMatcher:\n      serviceName: http-server-balancing-hostport-v4\n      namespace: default\n      toPorts:\n        - port: \"80\"\n          protocol: TCP\n          name: p2\n  backend:\n    serviceEndpoint:\n      endpointSelector:\n        matchLabels:\n          app: http-redirect\n      redirectMode: hostPort\n      toPorts:\n        - port: \"20080\"\n          protocol: TCP\n          name: p2\nEOF\n</code></pre> <p>In the following example, the front specifies a service in Kubernetes, and the backend forwards to the Proxy IP of the node where the Pod resides based on the pod's label selector.</p> <pre><code>apiVersion: balancing.elf.io/v1beta1\nkind: BalancingPolicy\nmetadata:\n  name: test-service-nodeproxy\nspec:\n  frontend:\n    serviceMatcher:\n      serviceName: http-server-balancing-nodeproxy-v4\n      namespace: default\n      toPorts:\n        - port: \"80\"\n          protocol: TCP\n          name: p2\n  backend:\n    serviceEndpoint:\n      endpointSelector:\n        matchLabels:\n          app: http-redirect\n      redirectMode: nodeProxy\n      toPorts:\n        - port: \"20080\"\n          protocol: TCP\n          name: p2\nEOF\n</code></pre> <p>In the following example, the front uses a custom virtual IP and port, and the backend uses a custom IP and port.</p> <pre><code>apiVersion: balancing.elf.io/v1beta1\nkind: BalancingPolicy\nmetadata:\n  name: test-addr\nspec:\n  frontend:\n    addressMatcher:\n      ip: \"169.254.169.254\"\n      toPorts:\n        - port: \"8080\"\n          protocol: TCP\n          name: p1\n        - port: \"80\"\n          protocol: TCP\n          name: p2\n  backend:\n    addressEndpoint:\n      addresses:\n        - \"1.1.1.1\"\n        - \"1.1.1.2\"\n      toPorts:\n        - port: \"80\"\n          protocol: TCP\n          name: p1\n        - port: \"80\"\n          protocol: TCP\n          name: p2\n</code></pre>"},{"location":"usages/install/","title":"Quick Start","text":""},{"location":"usages/install/#installation-requirements","title":"Installation Requirements","text":"<ol> <li> <p>Linux Kernel Requirements for Host: It is recommended that the Linux kernel version is greater than v5.8 to ensure all features function properly.</p> </li> <li> <p>Architecture Support: Currently, only AMD architecture images are provided, and ARM architecture images are not yet available.</p> </li> </ol>"},{"location":"usages/install/#deploying-balancing-in-a-kubernetes-cluster","title":"Deploying Balancing in a Kubernetes Cluster","text":"<pre><code># Get the API Server access address\n~# kubectl cluster-info\n  Kubernetes control plane is running at https://192.168.0.10:6443\n\n# Deploy Balancing, specifying the API Server access address separately, so that Balancing can access the API Server to complete its work even without running kube-proxy\n~# helm repo add elf https://elf-io.github.io/balancing\n~# helm install -n elf balancing elf/balancing \\\n    --set feature.apiServerHost=192.168.0.10 \\\n    --set feature.apiServerPort=6443\n\n~# kubectl get pod -n elf\n  NAME                                    READY   STATUS    RESTARTS   AGE\n  balancing-agent-jj8vq                   1/1     Running   0          4d10h\n  balancing-agent-wqs4g                   1/1     Running   0          4d10h\n  balancing-controller-849c9bd8f6-gbw6w   1/1     Running   0          4d10h\n</code></pre>"},{"location":"usages/install/#deploying-balancing-agent-container-service-on-hosts-outside-the-cluster","title":"Deploying Balancing Agent Container Service on Hosts Outside the Cluster","text":"<p>You can deploy the Balancing Agent container service on hosts outside the cluster, and its configuration file should specify the configuration of the Kubernetes cluster to connect to.</p> <pre><code>IMAGE_TAG=v0.0.2\ndocker run -d --net=host \\\n    --privileged \\\n    -e \"KUBECONFIG=/config\" \\\n    -v ./config:/config  \\\n    -v /sys/fs:/sys/fs:rw \\\n    -v /proc:/host/proc \\\n    ghcr.io/elf-io/balancing-agent:${IMAGE_TAG}\n</code></pre>"},{"location":"usages/localredirect/","title":"LocalRedirect Policy","text":""},{"location":"usages/localredirect/#introduction","title":"Introduction","text":"<p>The LocalRedirect policy is inspired by similar functionality in the cilium project. Based on cGroup eBPF technology, it redirects requests to local services on the same node when a Pod accesses specified services.</p> <p>It supports request redirection for the following objects: * Applications within Pods * Applications on cluster nodes</p> <p></p>"},{"location":"usages/localredirect/#features","title":"Features","text":"<p>The current version supports the following features:</p> <ul> <li> Frontend supports targeting services or custom VIPs and ports</li> <li> Backend supports Pod label selectors</li> <li> Supports configuring cluster-wide QoS limits</li> </ul> <p>Note: Between Balancing Policy and LocalRedirect Policy instances, the frontend does not support binding to the same service or defining the same virtual address, as this would cause resolution conflicts.</p> <p>When the frontend of a Balancing Policy or LocalRedirect Policy uses a custom IP address, if the IP address conflicts with a Kubernetes service ClusterIP, the policy's forwarding rules will take precedence for resolution.</p>"},{"location":"usages/localredirect/#use-cases","title":"Use Cases","text":"<ul> <li>Implementing transparent redirection for Node-local DNS   To improve CoreDNS service capability and avoid DNS avalanche effects, the open-source community introduced Node-local DNS to implement DNS caching on each node.</li> </ul> <p>In traditional approaches, the DNS configuration of Pods is modified to point to the virtual address of the local Node-local DNS, binding this virtual address on the node. However, when the Node-local DNS fails or is upgraded, this approach cannot provide high-availability DNS service for applications.</p> <p>By introducing the redirection capability of the LocalRedirect policy, transparent and highly available service redirection can be provided for Node-local DNS without modifying Pod DNS configurations or introducing new virtual addresses. This supports resolving service access to the original CoreDNS service during local Node-local DNS failures or upgrades.</p> <p>Optionally, cluster-wide QoS limits can be configured. On each node, when the redirection count for a service reaches the QoS limit per second, redirection will not be implemented for that service within the current second, allowing service resolution to follow the normal process. This feature can be used to effectively set the per-second QoS limit for node-local proxies.</p>"},{"location":"usages/localredirect/#policy-examples","title":"Policy Examples","text":"<p>Below is a YAML example where the frontend points to a service name:</p> <pre><code>apiVersion: balancing.elf.io/v1beta1\nkind: LocalRedirectPolicy\nmetadata:\n  name: test-service\nspec:\n  frontend:\n    serviceMatcher:\n      serviceName: http-server-v4\n      namespace: default\n      toPorts:\n        - port: \"8080\"\n          protocol: TCP\n          name: p1\n        - port: \"80\"\n          protocol: TCP\n          name: p2\n  backend:\n    endpointSelector:\n      matchLabels:\n        app: http-redirect\n    toPorts:\n      - port: \"80\"\n        protocol: TCP\n        name: p1\n      - port: \"80\"\n        protocol: TCP\n        name: p2\n</code></pre> <p>Below is a YAML example where the frontend uses a custom virtual IP and port:</p> <pre><code>apiVersion: balancing.elf.io/v1beta1\nkind: LocalRedirectPolicy\nmetadata:\n  name: test-addr\n  annotations:\n     balancing.elf.io/serviceId: \"10091\"\nspec:\n  frontend:\n    addressMatcher:\n      ip: \"169.254.0.90\"\n      toPorts:\n        - port: \"8080\"\n          protocol: TCP\n          name: p1\n        - port: \"80\"\n          protocol: TCP\n          name: p2\n  backend:\n    endpointSelector:\n      matchLabels:\n        app: http-redirect\n    toPorts:\n      - port: \"80\"\n        protocol: TCP\n        name: p1\n      - port: \"80\"\n        protocol: TCP\n        name: p2\n</code></pre>"},{"location":"usages/localredirect/#qos-rate-limiting","title":"QoS Rate Limiting","text":"<p>When the nodelocal redirection for a service on the local node reaches the per-second processing limit, other requests within that time unit will fall back to using the regular service resolution method to forward to the original backend service. This feature can provide rate limiting protection for local redirection proxies.</p> <ol> <li> <p>Enabling</p> <p>Method 1: When installing balancing, set the helm parameter values.feature.redirectQosLimit=100</p> <p>Method 2: After installing balancing, you can set <code>kubectl set env deployment/balancing-agent -n elf REDIRECT_QOS_LIMIT=100</code></p> </li> </ol>"},{"location":"usages/service/","title":"Service Resolution","text":""},{"location":"usages/service/#introduction","title":"Introduction","text":"<p>The Service resolution feature is inspired by projects like Cilium , Calico , and KPNG . It provides CNI-independent load balancing resolution capabilities.</p> <p>It can redirect requests sent by the following objects: * Applications within Pods * Applications on cluster nodes * Applications on external hosts</p>"},{"location":"usages/service/#features","title":"Features","text":"<p>Currently, it has the following features:</p> <ul> <li> East-west Service resolution for Pods and Nodes: Supports accessing ClusterIP, NodePort, LoadBalancer, ExternalIP, supports sessionAffinity based on ClientIP, and supports internalTrafficPolicy set to Local.</li> <li> For applications on external hosts, it generally supports Service address resolution, including ClusterIP, NodePort, LoadBalancer, ExternalIP. However, Balancing resolves to Pod IP addresses, making it suitable for scenarios using underlay CNIs like Macvlan , Spiderpool , or scenarios using Calico with BGP propagated cluster Pod routes.</li> </ul> <p>In future versions, the following issues will be addressed:</p> <ul> <li> North-south Service resolution on Nodes: Supports resolving Service access requests sent from outside the cluster, including NodePort, LoadBalancer, ExternalIP, supports sessionAffinity based on ClientIP, and supports externalTrafficPolicy set to Local.</li> <li> For existing sessionAffinity=ClientIP forwarding records, it should follow the health status of backend Pods, and persistent forwarding should be interrupted when a backend Pod is unavailable.</li> </ul>"},{"location":"usages/service/#use-cases","title":"Use Cases","text":"<ul> <li> <p>Compared to traditional technologies like iptables, the eBPF-based implementation offers superior Service resolution performance, avoiding the troubleshooting pain of iptables.</p> </li> <li> <p>It is CNI-independent, enabling eBPF Service resolution for many CNI projects that do not have eBPF technology, such as Antrea , Kube-ovn , Flannel , and some public cloud Kubernetes clusters like Amazon VPC CNI , Azure CNI . Additionally, it is suitable for many underlay CNIs, solving the inherent issue of not being able to access Services due to the data packet forwarding path, such as Macvlan , SR-IOV CNI , Spiderpool , OVS-CNI .</p> </li> </ul> <p>Cilium and Calico come with kube-proxy replacement functionality and do not require the Balancing project.</p>"},{"location":"zh/readme/","title":"Balancing","text":"<p>\u76ee\u524d\uff0cBalancing \u5904\u4e8e\u5f00\u53d1\u6d4b\u8bd5\u9636\u6bb5\uff0c\u4e0d\u9002\u5408\u7528\u4e8e\u751f\u4ea7\u73af\u5883\u3002</p>"},{"location":"zh/readme/#balancing_1","title":"Balancing \u7b80\u4ecb","text":"<p>Balancing \u662f\u4e00\u4e2a\u5728 Kubernetes \u5e73\u53f0\u4e0a\u57fa\u4e8e eBPF \u5b9e\u73b0\u7684\u56db\u5c42\u8d1f\u8f7d\u5747\u8861\u7ec4\u4ef6\u3002\u5b83\u53c2\u8003\u4e86 cilium \u3001calico \u3001KPNG  \u7b49\u9879\u76ee\u7684\u529f\u80fd\uff0c Balancing \u652f\u6301\u4ee5\u5bb9\u5668\u5316\u65b9\u5f0f\u8fd0\u884c\u5728 Kubernetes \u96c6\u7fa4\u5185\u90e8\uff0c\u4e5f\u652f\u6301\u4e8c\u8fdb\u5236\u65b9\u5f0f\u8fd0\u884c\u5728\u88f8\u91d1\u5c5e\u4e0a\uff0c\u4e3a Kubernetes \u96c6\u7fa4\u5185\u90e8\u5e94\u7528\u3001\u5916\u90e8\u5e94\u7528\u5b9e\u73b0\u4e86\u4e0e CNI \u65e0\u5173\u7684\u8d1f\u8f7d\u5747\u8861\u8bbf\u95ee\u80fd\u529b\u3002</p>"},{"location":"zh/readme/#_1","title":"\u5f53\u524d\u529f\u80fd","text":"<ol> <li> <p>\u5b9e\u65bd CNI \u65e0\u5173\u7684\u96c6\u7fa4 service \u89e3\u6790</p> <ul> <li>\u57fa\u4e8e cGroup eBPF \uff0c\u5728\u96c6\u7fa4\u8282\u70b9\u4e0a\u4e3a Pod \u548c Node \u53d1\u8d77\u7684 service \u8bbf\u95ee\u5b9e\u65bd\u89e3\u6790\uff0c\u5b9e\u73b0 kube-proxy replacement\u3002</li> <li>\u5728\u96c6\u7fa4\u5916\u7684\u88f8\u91d1\u5c5e\u3001\u865a\u62df\u673a\u4e0a\u5b9e\u65bd\u5ba2\u6237\u7aef\u8d1f\u8f7d\u5747\u8861\u89e3\u6790\uff0c\u4ee5\u652f\u6301\u8bbf\u95ee kubernetes \u96c6\u7fa4\u4e2d\u7684 service\u3002</li> <li>\u672a\u6765\u7248\u672c\u5c06\u652f\u6301\u5728\u8282\u70b9\u7f51\u5361\u4e0a\u57fa\u4e8e TC eBPF \u5b9e\u73b0\u5357\u5317\u5411\u7684 nodePort \u89e3\u6790\u3002</li> <li>\u66f4\u591a\u4fe1\u606f\uff0c\u8bf7\u53c2\u8003 service\u89e3\u6790</li> </ul> </li> <li> <p>\u5b9e\u65bd\u672c\u5730\u91cd\u5b9a\u5411\u7684\u56db\u5c42\u8d1f\u8f7d\u5747\u8861\u89e3\u6790\uff1a</p> <ul> <li>\u57fa\u4e8e cGroup eBPF\uff0c\u4e3a Pod \u548c Node \u53d1\u8d77\u7684 service \u8bbf\u95ee\u91cd\u5b9a\u5411\u89e3\u6790\u5230\u540c\u8282\u70b9\u4e0a\u7684\u670d\u52a1\uff0c\u5178\u578b\u573a\u666f\u5982 local coreDns\u3002</li> <li>\u66f4\u591a\u4fe1\u606f\uff0c\u8bf7\u53c2\u8003 LocalRedirect Policy</li> </ul> </li> <li> <p>\u5b9e\u65bd\u96c6\u7fa4\u5168\u5c40\u3001\u96c6\u7fa4\u5916\u90e8\u670d\u52a1\u7684\u56db\u5c42\u8d1f\u8f7d\u5747\u8861\u89e3\u6790\uff1a</p> <ul> <li>\u652f\u6301\u66f4\u52a0\u7075\u6d3b\u7684\u7b56\u7565\u5b9a\u4e49\uff0c\u4e3a\u96c6\u7fa4\u5185\u90e8\u548c\u5916\u90e8\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u5168\u5c40\u7684\u8d1f\u8f7d\u5747\u8861\u7b56\u7565\u3002</li> <li>\u5e94\u7528\u573a\u666f\u5305\u62ec\u96c6\u7fa4\u5916\u90e8\u4e3b\u673a\u7684\u5ba2\u6237\u7aef\u4fa7\u8d1f\u8f7d\u5747\u8861\u89e3\u6790\u3001Kubernetes \u96c6\u7fa4\u5185\u7684\u8d1f\u8f7d\u5747\u8861\u7b49\u3002</li> <li>\u66f4\u591a\u4fe1\u606f\uff0c\u8bf7\u53c2\u8003 Balancing Policy</li> </ul> </li> <li> <p>\u89e3\u6790\u4e8b\u4ef6\u7684\u6307\u6807\u65e5\u5fd7\uff1a</p> <ul> <li>\u8bb0\u5f55\u8d1f\u8f7d\u5747\u8861\u89e3\u6790\u4e8b\u4ef6\uff0c\u5e76\u5173\u8054\u5bb9\u5668\u4fe1\u606f\uff0c\u5f62\u6210\u5b8c\u6574\u7684\u8d1f\u8f7d\u5747\u8861\u89e3\u6790\u6307\u6807\u3002</li> </ul> </li> </ol>"},{"location":"zh/readme/#_2","title":"\u5178\u578b\u4f7f\u7528\u573a\u666f","text":"<ol> <li> <p>\u5728 CNI \u65e0\u5173\u7684\u96c6\u7fa4\u4e2d\uff0c\u66ff\u4ee3 kube-proxy \u7684 service \u89e3\u6790\uff1a</p> <ul> <li>\u9002\u7528\u4e8e\u65e0\u6cd5\u5b9e\u65bd service \u7684 underlay CNI\uff0c\u5982 Macvlan \u3001SR-IOV CNI  \u7b49\u3002</li> <li>\u9002\u7528\u4e8e\u6ca1\u6709\u5b9e\u73b0 eBPF \u529f\u80fd\u7684CNI\uff0c\u5982 Antrea \u3001 Kube-ovn \u3001 Flannel \uff0c\u4ee5\u53ca\u516c\u6709\u4e91\u96c6\u7fa4\u3002</li> </ul> </li> <li> <p>\u670d\u52a1\u8bbf\u95ee\u91cd\u5b9a\u5411\u5230\u672c\u5730\u4ee3\u7406\uff1a</p> <ul> <li>\u5b9e\u65bd\u9ad8\u53ef\u7528\u7684\u91cd\u5b9a\u5411\uff0c coreDns \u670d\u52a1\u5b9a\u5411\u5230 Node-local DNS</li> <li>\u4e3a clusterpedia \u5b9e\u65bd\u8282\u70b9 api-server \u4ee3\u7406</li> </ul> </li> <li> <p>\u96c6\u7fa4\u5916\u90e8\u7684\u5ba2\u6237\u7aef\u5e94\u7528\u4fa7\u5b9e\u65bd eBPF \u56db\u5c42\u8d1f\u8f7d\u5747\u8861\uff0c\u8bbf\u95ee Kubernetes \u96c6\u7fa4\u4e2d\u7684\u670d\u52a1\uff1a</p> <ul> <li>\u88f8\u91d1\u5c5e\u3001\u865a\u62df\u673a\u4e2d\u7684\u5e94\u7528</li> <li>kubevirt \u865a\u62df\u673a\u4e2d\u7684\u5e94\u7528</li> <li>kubeedge \u8fb9\u7aef\u8282\u70b9\u8bbf\u95ee\u4e91\u7aef\u670d\u52a1\uff08\u8fdb\u884c\u4e2d\uff09</li> </ul> </li> <li> <p>\u591a\u96c6\u7fa4\u4e4b\u95f4\u7684\u56db\u5c42\u8d1f\u8f7d\u5747\u8861\u8bbf\u95ee\u3002</p> <ul> <li>\u8de8\u96c6\u7fa4\u7684\u670d\u52a1\u8bbf\u95ee \uff08\u8fdb\u884c\u4e2d\uff09</li> </ul> </li> <li> <p>\u901a\u8fc7\u81ea\u5b9a\u4e49\u7684\u524d\u7aef\u548c\u540e\u7aef\u5730\u5740\uff0c\u5728 kubernetes \u96c6\u7fa4\u4e2d\u63d0\u4f9b\u5916\u90e8\u4e3b\u673a\u670d\u52a1\u7684\u8d1f\u8f7d\u5747\u8861\u8bbf\u95ee</p> <ul> <li>\u901a\u8fc7\u81ea\u5b9a\u4e49\u7684\u8d1f\u8f7d\u5747\u8861\u7b56\u7565\uff0c\u4e3a\u96c6\u7fa4\u5916\u90e8\u7684\u5e94\u7528\u63d0\u4f9b\u96c6\u7fa4\u5185\u90e8\u7684\u8d1f\u8f7d\u5747\u8861\u8bbf\u95ee\u5730\u5740\uff0c\u5e76\u5b9e\u65bd\u5065\u5eb7\u68c0\u67e5\uff08\u8fdb\u884c\u4e2d\uff09</li> </ul> </li> </ol>"},{"location":"zh/readme/#_3","title":"\u67b6\u6784","text":"<p>Balancing \u7ec4\u4ef6\u7531 agent \u548c controller \u6784\u6210\uff1a - controller deployment\uff1a\u5b9e\u65bd\u5404\u79cd CRD \u5bf9\u8c61\u7684 webhook \u6821\u9a8c\u548c\u4fee\u6539\u3002 - agent daemonset\uff1a\u52a0\u8f7d eBPF \u7a0b\u5e8f\u5e76\u4e0b\u53d1\u8f6c\u53d1\u89c4\u5219\u3002</p> <p></p>"},{"location":"zh/readme/#_4","title":"\u5feb\u901f\u5f00\u59cb","text":"<ul> <li>\u53c2\u8003 \u5b89\u88c5 \u5feb\u901f\u90e8\u7f72\u3002</li> <li>\u53c2\u8003 service \u89e3\u6790 \u8fdb\u884c\u4f7f\u7528\u4f53\u9a8c\u3002</li> <li>\u53c2\u8003 LocalRedirect Policy \u8fdb\u884c\u4f7f\u7528\u4f53\u9a8c\u3002</li> <li>\u53c2\u8003 Balancing Policy \u8fdb\u884c\u4f7f\u7528\u4f53\u9a8c\u3002</li> </ul>"},{"location":"zh/readme/#_5","title":"\u8def\u7ebf\u56fe","text":"<ul> <li>IP \u5bb6\u65cf\u548c\u534f\u8bae</li> <li> \u652f\u6301 TCP \u548c UDP</li> <li> \u652f\u6301 IPv4</li> <li> <p> \u652f\u6301 IPv6</p> </li> <li> <p>\u53ef\u89c2\u6d4b\u6027</p> </li> <li> \u8d1f\u8f7d\u5747\u8861\u89e3\u6790\u65e5\u5fd7</li> <li> <p> \u8d1f\u8f7d\u5747\u8861\u89e3\u6790\u6307\u6807</p> </li> <li> <p>service \u89e3\u6790</p> </li> <li> \u4e1c\u897f\u5411 service \u89e3\u6790</li> <li> \u5357\u5317\u5411 service \u89e3\u6790</li> <li> <p> sessionAffinity \u8f6c\u53d1\u8bb0\u5f55\u5065\u5eb7\u72b6\u6001</p> </li> <li> <p>LocalRedirect Policy</p> </li> <li> front \u652f\u6301\u6307\u5411 service \u548c\u81ea\u5b9a\u4e49 VIP</li> <li> <p> backend \u652f\u6301 pod \u6807\u7b7e\u9009\u62e9\u5668</p> </li> <li> <p>Balancing Policy</p> </li> <li> front \u652f\u6301\u6307\u5411 service \u548c\u81ea\u5b9a\u4e49 VIP</li> <li> backend \u652f\u6301 pod \u6807\u7b7e\u9009\u62e9\u5668</li> <li> backend \u652f\u6301\u81ea\u5b9a\u4e49 IP \u548c\u7aef\u53e3</li> <li> <p> \u8282\u70b9\u95f4\u8f6c\u53d1\u96a7\u9053</p> </li> <li> <p>\u591a\u96c6\u7fa4\u4e92\u8054</p> </li> <li> \u8de8\u96c6\u7fa4\u7684 service \u4e92\u8054</li> <li> <p> \u8de8\u96c6\u7fa4\u7684 balancing policy</p> </li> <li> <p>\u5176\u5b83</p> </li> <li> \u652f\u6301 amd \u67b6\u6784</li> <li> \u652f\u6301 arm \u67b6\u6784</li> </ul>"},{"location":"zh/readme/#_6","title":"\u8bb8\u53ef\u8bc1","text":"<p>Balancing \u9075\u5faa Apache License, Version 2.0 \u8bb8\u53ef\u534f\u8bae\u3002\u8be6\u89c1 LICENSE\u3002</p>"},{"location":"zh/develop/develop/","title":"\u642d\u5efa\u5f00\u53d1\u73af\u5883","text":""},{"location":"zh/develop/develop/#_2","title":"\u4e3b\u673a\u8f6f\u4ef6\u51c6\u5907","text":"<ul> <li>Vvagrant \u548c VirtualBox</li> <li>helm</li> <li>kubectl</li> <li>jq</li> </ul>"},{"location":"zh/develop/develop/#vagrant","title":"\u57fa\u4e8e Vagrant \u865a\u62df\u673a\u642d\u5efa\u672c\u5730\u5f00\u53d1\u73af\u5883","text":"<ol> <li> <p>\u6784\u5efa balancing \u955c\u50cf</p> <pre><code>make build_local_image\n\n# \u5bf9\u4e8e\u4e2d\u56fd\u533a\u7528\u6237\uff0c\u53ef\u4ee5\u4f7f\u7528\u4ee3\u7406\u6e90\u6765\u52a0\u901f\u6784\u5efa\nmake build_local_image -e USE_PROXY_SOURCE=true\n</code></pre> </li> <li> <p>\u6784\u5efa\u6d4b\u8bd5\u5e94\u7528\u955c\u50cf</p> <pre><code>make build_local_test_app_image\n</code></pre> </li> <li> <p>\u90e8\u7f72\u57fa\u4e8e\u865a\u62df\u673a\u7684\u53cc\u8282\u70b9 Kubernetes \u96c6\u7fa4\uff08\u4e0d\u5b89\u88c5 kube-proxy \u7ec4\u4ef6\uff09</p> <pre><code>make e2e_init -e E2E_SKIP_KUBE_PROXY=true -e E2E_INSTALL_PYROSCOPE=false\n</code></pre> </li> <li> <p>\u90e8\u7f72 balancing \u548c\u6d4b\u8bd5\u5e94\u7528\u5230\u96c6\u7fa4\u4e2d</p> <pre><code>make e2e_deploy -e E2E_REDIRECT_QOS_LIMIT=1\n\n# \u6216\u8005\u4f7f\u7528\u6307\u5b9a\u7684\u955c\u50cf\u6807\u7b7e\nmake e2e_deploy -e PROJECT_IMAGE_TAG=8877a79da7c0a9f159363660b5b23e5458480aea \\\n                -e TEST_APP_IMAGE_TAG=aa7693a44e205c13e9bd3bee63260c9c1048ce24\n</code></pre> </li> <li> <p>\u6d4b\u8bd5 balancing \u7684\u5404\u79cd\u7b56\u7565\u4f8b\u5b50</p> <pre><code>make e2e_test_connectivity\n</code></pre> </li> <li> <p>\u4f7f\u7528\u6d4f\u89c8\u5668\u8bbf\u95ee <code>http://NodeIP:28000</code>\uff0c\u67e5\u770b Proscope Server \u4e2d\u7684 Golang \u91c7\u6837\u6570\u636e\u3002</p> </li> </ol>"},{"location":"zh/develop/develop/#ebpf","title":"\u672c\u673a\u8c03\u8bd5 ebpf","text":"<pre><code>apt-get install clang llvm gcc-multilib libbpf-dev linux-headers-$(uname -r)\n\ncd pkg/ebpf/bpf\n\n# \u68c0\u6d4b\u8bed\u6cd5\u9519\u8bef\nclang -fsyntax-only -I.  cgroup.c\n</code></pre>"},{"location":"zh/develop/ebpfDebug/","title":"eBPF \u8c03\u8bd5","text":"<p>\u5728\u90e8\u7f72 Balancing \u540e\uff0c\u53ef\u68c0\u6d4b\u5982\u4e0b\u5185\u5bb9\uff0c\u786e\u8ba4 Balancing \u5de5\u4f5c\u7b26\u5408\u9884\u671f\u3002</p>"},{"location":"zh/develop/ebpfDebug/#ebpf-map","title":"eBPF map \u4f5c\u7528","text":"<pre><code>map_service\n    \u8bb0\u5f55\u4e86\u4e3a\u6bcf\u4e00\u4e2a service \u751f\u6210\u7684\u8bbf\u95ee\u5165\u53e3\u89c4\u5219\uff0c\u4e3a port\u3001nodeport\u3001Loadbalancer\u3001externalIP \u5206\u522b\u90fd\u4f1a\u751f\u6210\u4e00\u6761\u8bb0\u5f55 \n\nmap_backend\n    \u8bb0\u5f55\u4e86\u6bcf\u4e00\u4e2a\u540e\u7aef endpoint \u7684\u8f6c\u53d1\u5730\u5740\uff0c\u6bcf\u4e00\u4e2a endpoint \u90fd\u4f1a\u6709\u4e00\u4e2a\u8bb0\u5f55\uff0c\u5982\u679c\u662fnodePort \u573a\u666f\uff0c\u8bb0\u5f55\u6570\u91cf\u518d\u7ffb\u500d\n\nmap_affinity\n    \u5b58\u50a8\u5ba2\u6237\u7aef\u4eb2\u548c\u8bb0\u5f55\uff0c\u5b9e\u73b0\u4f1a\u8bdd\u4eb2\u548c\u6027\n\nmap_nat_record\n    \u8bb0\u5f55\u4e86 nat \u94fe\u8def\u8ffd\u8e2a\n\nmap_node_proxy_ip\n    \u8bb0\u5f55\u4e86 \u8282\u70b9\u7684 id \u548c ip \u7684\u6620\u5c04 , \u7528\u4e8e\u5176\u5b83\u8868\u683c\u5728\u67e5\u8be2\u65f6\u8fdb\u884c id \u548c ip \u4e4b\u95f4\u7684\u7d22\u5f15\n\nmap_node_ip\n    \u8bb0\u5f55\u4e86\u6bcf\u4e00\u4e2a node \u7684 ip \uff0c\u7528\u4e8e\u5339\u914d nodePort \u573a\u666f\u4e0b\u7684 \u76ee\u7684 ip\n\nmap_configure\n    ebpf \u7a0b\u5e8f\u7684\u5b9e\u65f6\u5de5\u4f5c\u914d\u7f6e\n</code></pre>"},{"location":"zh/develop/ebpfDebug/#ebpf_1","title":"\u8282\u70b9 eBPF \u68c0\u67e5","text":"<pre><code># \u5728\u4e3b\u673a\u5982\u4e0b\u76ee\u5f55\uff0c\u6302\u8f7d\u4e86 eBPF map\nls /sys/fs/bpf/balancing/\n# \u8f93\u51fa\u793a\u4f8b\nmap_affinity  map_backend  map_configure  map_event  map_nat_record  map_node_ip  map_node_proxy_ip  map_service\n\n# \u4f7f\u7528\u5982\u4e0b\u547d\u4ee4\u80fd\u591f\u67e5\u8be2\u5230 balancing eBPF map\nbpftool map\n\n# \u4e3b\u673a\u5982\u4e0b\u76ee\u5f55\u6302\u8f7d\u4e86 cgroup v2\nls /sys/fs/cgroup\n# \u8f93\u51fa\u793a\u4f8b\ncgroup.controllers  cgroup.stat  cpuset.cpus.isolated  dev-mqueue.mount  io.prio.class  memory.reclaim  proc-sys-fs-binfmt_misc.mount  system.slice\n\n# \u4f7f\u7528\u5982\u4e0b\u547d\u4ee4\u80fd\u591f\u67e5\u8be2\u5230 balancing \u52a0\u8f7d\u7684 cgroup_sock_addr \u7c7b\u578b\u7684 eBPF Program\nbpftool prog\n\n# \u4f7f\u7528\u5982\u4e0b\u547d\u4ee4\u80fd\u591f\u67e5\u8be2\u5230 balancing \u628a eBPF Program \u5173\u8054\u5230\u4e86 cgroup v2\nbpftool cgroup tree /run/balancing/cgroupv2\n\n# \u4e3b\u673a\u4e0a\u67e5\u770b eBPF \u7a0b\u5e8f\u6253\u5370\u51fa\u7684\u65e5\u5fd7\nbpftool prog tracelog\n# \u6216\ncat /sys/kernel/debug/tracing/trace_pipe\n</code></pre>"},{"location":"zh/develop/ebpfDebug/#balancing-agent","title":"\u786e\u8ba4 Balancing agent \u65e5\u5fd7","text":"<pre><code># \u67e5\u8be2 agent pod \u7684\u8d1f\u8f7d\u5747\u8861\u89e3\u6790\u4e8b\u4ef6\u65e5\u5fd7\nkubectl logs -n elf balancing-agent-q727g | grep \"formatted ebpf event\" | jq .\n</code></pre>"},{"location":"zh/develop/ebpfDebug/#_1","title":"\u5bf9\u8c61","text":"<p>\u5982\u4e0b\u8fd9\u4e9b\u5bf9\u8c61\u7684 id\uff0c \u90fd\u662f\u7528\u5728 ebpf \u7684 map \u4e2d\u4ee3\u8868\u76f8\u5173\u5bf9\u8c61</p> <pre><code># \u786e\u8ba4\u6bcf\u4e00\u4e2a\u8282\u70b9\uff0c\u90fd\u88ab\u6807\u8bb0\u4e86\u5982\u4e0b ID \u552f\u4e00\u7684 annotation\nkubectl get nodes -o jsonpath='{.items[*].metadata.annotations}' | jq .\n# \u8f93\u51fa\u793a\u4f8b\n{\n  \"balancing.elf.io/nodeId\": \"596592060\",\n  \"balancing.elf.io/nodeProxyIpv4\": \"192.168.0.10\",\n  ...\n}\n</code></pre> <pre><code># \u6240\u6709\u7684 balancingpolicies \uff0c\u90fd\u6709\u4e00\u4e2a\u552f\u4e00\u7684 id\nkubectl get balancingpolicies -o jsonpath='{.items[*].metadata.annotations}' | jq .\n# \u8f93\u51fa\u793a\u4f8b\n{\n  \"balancing.elf.io/serviceId\": \"20003\",\n  ...\n}\n</code></pre> <pre><code># \u6240\u6709\u7684 localredirectpolicies \uff0c\u90fd\u6709\u4e00\u4e2a\u552f\u4e00\u7684 id\nkubectl get localredirectpolicies -o jsonpath='{.items[*].metadata.annotations}' | jq .\n# \u8f93\u51fa\u793a\u4f8b\n{\n  \"balancing.elf.io/serviceId\": \"10091\",\n  ...\n}\n</code></pre>"},{"location":"zh/develop/ebpfDebug/#ebpf_2","title":"\u67e5\u770b eBPF \u4e2d\u7684\u6570\u636e","text":"<p>\u8fdb\u5165 agent pod \u4e2d\uff0c\u53ef\u4f7f\u7528 inspect \u547d\u4ee4\u67e5\u770b eBPF map \u4e2d\u7684\u6570\u636e\u3002</p> <pre><code># \u67e5\u8be2\u6240\u6709 ebpf map \u4e2d\u7684\u6570\u636e\ninspect showMapData all\n\n# \u8ffd\u8e2a\u6307\u5b9a service \u76f8\u5173\u7684 ebpf map \u6570\u636e\ninspect traceMapData service $namespace $serviceName\n\n# \u8ffd\u8e2a\u6307\u5b9a localredirectpolicies \u76f8\u5173\u7684 ebpf map \u6570\u636e\ninspect traceMapData localRedirect $namespace $policyName\n\n# \u8ffd\u8e2a\u6307\u5b9a balancingpolicies \u76f8\u5173\u7684 ebpf map \u6570\u636e\ninspect traceMapData balancing $namespace $serviceName\n</code></pre>"},{"location":"zh/usages/balancing/#_1","title":"\u7b80\u4ecb","text":"<p>Balancing Policy \u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u8d1f\u8f7d\u5747\u8861\u6a21\u5f0f\uff0c\u8865\u5145\u4e86 Kubernetes \u7684 service\uff0c\u5b9e\u73b0\u4e86\u96c6\u7fa4\u7684\u5168\u5c40\u56db\u5c42\u8d1f\u8f7d\u5747\u8861\u3002</p> <p>\u5b83\u652f\u6301\u4ee5\u4e0b\u5bf9\u8c61\u7684\u8bf7\u6c42\u91cd\u5b9a\u5411\uff1a * Pod \u4e2d\u7684\u5e94\u7528 * \u96c6\u7fa4\u8282\u70b9\u4e0a\u7684\u5e94\u7528 * \u96c6\u7fa4\u5916\u90e8\u4e3b\u673a\u4e0a\u7684\u5e94\u7528</p>"},{"location":"zh/usages/balancing/#_2","title":"\u529f\u80fd","text":"<p>\u5f53\u524d\u529f\u80fd\u5305\u62ec\uff1a * [x] \u81ea\u5b9a\u4e49\u8d1f\u8f7d\u5747\u8861\u7684 front \u5730\u5740\uff0c\u53ef\u4ee5\u662f Kubernetes \u7684 service name \u6216\u81ea\u5b9a\u4e49\u7684 VIP \u548c\u7aef\u53e3\u3002 * [x] \u81ea\u5b9a\u4e49\u8d1f\u8f7d\u5747\u8861\u7684 backend \u5730\u5740\uff0c\u901a\u8fc7 pod label selector \u6307\u5b9a\u540e\u7aef\u5bf9\u8c61\uff0c\u652f\u6301\u4ee5\u4e0b\u4e09\u79cd\u65b9\u5f0f\uff1a     * endpoint IP\uff1a\u8d1f\u8f7d\u5747\u8861\u5730\u5740\u88ab DNAT \u89e3\u6790\u4e3a pod IP\uff0c\u9002\u7528\u4e8e\u96c6\u7fa4\u5185\u7684\u4f20\u7edf\u4e3b\u673a\u5e94\u7528\u8bbf\u95ee\u4e00\u4e2a VIP \u5730\u5740\u3002     * HostPort\uff1a\u8d1f\u8f7d\u5747\u8861\u5730\u5740\u88ab DNAT \u89e3\u6790\u4e3a pod \u6240\u5728\u7684 node IP \u548c pod HostPort\uff0c\u9002\u7528\u4e8e\u96c6\u7fa4\u5916\u90e8\u5e94\u7528\u8bbf\u95ee\u96c6\u7fa4\u5185\u5b9a\u4e49\u4e86 hostPort \u7684 service     * nodeProxy\uff1a\u8d1f\u8f7d\u5747\u8861\u5730\u5740\u88ab DNAT \u89e3\u6790\u4e3a\u8282\u70b9\u7684 Proxy IP \u548c\u7b56\u7565\u4e2d\u5b9a\u4e49\u7684\u7aef\u53e3\uff0c\u9002\u7528\u96c6\u7fa4\u5916\u90e8\u5e94\u7528\u8bbf\u95ee\u96c6\u7fa4\u5185\u7684 POD, \u800c\u6539\u5165\u53e3\u5730\u5740\u662f\u516c\u6709\u4e91\u7684 Loadbalancer \uff0c \u6216\u8005\u7531 kube-proxy \u5b9e\u65bd\u7684 nodeport \u3002\u8282\u70b9\u7684 Proxy IP \u5b9a\u4e49\u5728 node \u5bf9\u8c61\u7684 annotation <code>\"balancing.elf.io/nodeProxyIpv4\": \"192.168.0.10\"</code>\uff0c\u53ef\u901a\u8fc7\u4ee5\u4e0b\u65b9\u5f0f\u751f\u6210\uff1a         * Balancing agent \u81ea\u52a8\u5728\u8282\u70b9\u4e0a\u5efa\u7acb\u96a7\u9053\u63a5\u53e3\uff0c\u5e76\u66f4\u65b0\u5230 node \u7684 annotation \u4e2d\uff0c\u9002\u7528\u4e8e\u591a\u96c6\u7fa4\u6216\u96c6\u7fa4\u5916\u90e8\u4e3b\u673a\u5e94\u7528\u3002         * \u7ba1\u7406\u5458\u53ef\u5728 Node \u5bf9\u8c61\u4e0a\u624b\u52a8\u8bbe\u7f6e annotation <code>\"balancing.elf.io/nodeProxyIpv4\"</code>\uff0c\u4f8b\u5982\u4ee3\u7406\u6620\u5c04 IP \u6216\u516c\u7f51\u6620\u5c04 IP\u3002</p> <p>\u6ce8\u610f\uff1aBalancing Policy \u548c LocalRedirect Policy \u5b9e\u4f8b\u4e4b\u95f4\u7684 front \u4e0d\u652f\u6301\u7ed1\u5b9a\u76f8\u540c\u7684 service \u6216\u5b9a\u4e49\u76f8\u540c\u7684\u865a\u62df\u5730\u5740\uff0c\u5426\u5219\u4f1a\u5bfc\u81f4\u89e3\u6790\u51b2\u7a81\u3002</p> <p>\u5982\u679c Balancing Policy \u6216 LocalRedirect Policy \u7684 front \u4f7f\u7528\u4e86\u81ea\u5b9a\u4e49 IP \u5730\u5740\uff0c\u5e76\u4e0e\u67d0\u4e2a Kubernetes \u7684 service ClusterIP \u51b2\u7a81\uff0c\u5219\u4f18\u5148\u6309\u7167 Balancing Policy \u6216 LocalRedirect Policy \u7684\u89c4\u5219\u89e3\u6790\u3002</p> <p>\u672a\u6765\u7248\u672c\u5c06\u89e3\u51b3\u4ee5\u4e0b\u95ee\u9898\uff1a * [ ] Balancing Agent \u652f\u6301\u81ea\u52a8\u5728\u8282\u70b9\u95f4\u5efa\u7acb\u8f6c\u53d1\u96a7\u9053\uff0c\u5e76\u66f4\u65b0 IP \u5730\u5740\u5230 node \u7684 annotation <code>\"balancing.elf.io/nodeProxyIpv4\"</code>\uff0c\u4ee5\u5b9e\u73b0 overlay CNI \u573a\u666f\u4e0b\u7684\u96c6\u7fa4\u5916\u90e8\u4e3b\u673a\u5e94\u7528\u548c\u591a\u96c6\u7fa4\u901a\u4fe1\u3002 * [ ] Balancing Agent \u5b9e\u65bd\u5bf9\u540e\u7aef\u81ea\u5b9a\u4e49\u7684 IP \u5730\u5740\u8fdb\u884c\u5065\u5eb7\u68c0\u67e5</p>"},{"location":"zh/usages/balancing/#_3","title":"\u4f7f\u7528\u573a\u666f","text":"<ol> <li>\u5728\u96c6\u7fa4\u5916\u90e8\u4e3b\u673a\u3001kubevirt \u865a\u62df\u673a\u3001kubedge \u8fb9\u7f18\u8282\u70b9\u4e0a\u8fd0\u884c balancing agent \u4e8c\u8fdb\u5236\u6216 docker \u670d\u52a1\uff0c\u8bbf\u95ee Kubernetes \u96c6\u7fa4\u4e2d\u7684\u670d\u52a1\u3002</li> </ol> <p>\u4f20\u7edf\u7684 nodePort \u6216 Loadbalancer \u8d1f\u8f7d\u5747\u8861\u53ef\u80fd\u4f1a\u9047\u5230 SNAT \u6e90\u7aef\u53e3\u51b2\u7a81\u3001\u957f\u8fde\u63a5\u8d85\u65f6\u7b49\u95ee\u9898\uff0c\u6210\u4e3a\u9ad8\u5e76\u53d1\u8bbf\u95ee\u7684\u74f6\u9888\u3002balancing \u63d0\u4f9b\u7684\u65b0\u65b9\u6848\u80fd\u591f\u5b9e\u73b0\u5ba2\u6237\u7aef\u4fa7\u7684\u8d1f\u8f7d\u5747\u8861\u89e3\u6790\uff0c\u51cf\u5c11\u8f6c\u53d1\u8def\u5f84\uff0c\u964d\u4f4e\u6392\u969c\u96be\u5ea6\u3002</p> <pre><code>&gt; \u5f53\u524d\u7248\u672c\u4e2d\uff0cBalancing \u5c1a\u672a\u5b8c\u6210\u8282\u70b9\u95f4\u7684\u96a7\u9053\u5efa\u7acb\u548c\u7aef\u53e3\u5206\u914d\uff0c\u56e0\u6b64\u53ea\u80fd\u5728 underlay CNI \u573a\u666f\u4e0b\u4fdd\u969c\u96c6\u7fa4\u5185\u5916\u7684\u8054\u901a\u3002\u672a\u6765\u7248\u672c\u4e2d\uff0cBalancing \u5b8c\u6210\u96a7\u9053\u5efa\u7acb\u540e\uff0c\u624d\u80fd\u4fdd\u969c overlay CNI \u573a\u666f\u4e0b\u7684\u96c6\u7fa4\u5185\u5916\u8fde\u901a\u6027\u3002\n</code></pre> <ol> <li>\u5b9e\u73b0\u591a\u96c6\u7fa4\u4e4b\u95f4\u7684\u56db\u5c42\u8d1f\u8f7d\u5747\u8861\u8bbf\u95ee\u3002</li> </ol> <p>\u5f53\u524d\u7248\u672c\u4e2d\uff0cBalancing \u5c1a\u672a\u5b8c\u6210\u8282\u70b9\u95f4\u7684\u96a7\u9053\u5efa\u7acb\u548c\u7aef\u53e3\u5206\u914d\uff0c\u56e0\u6b64\u53ea\u80fd\u5728 underlay CNI \u573a\u666f\u4e0b\u4fdd\u969c\u96c6\u7fa4\u5185\u5916\u7684\u8054\u901a\u3002\u672a\u6765\u7248\u672c\u4e2d\uff0cBalancing \u5b8c\u6210\u96a7\u9053\u5efa\u7acb\u540e\uff0c\u624d\u80fd\u4fdd\u969c overlay CNI \u573a\u666f\u4e0b\u7684\u96c6\u7fa4\u5185\u5916\u8fde\u901a\u6027\u3002</p> <ol> <li> <p>\u96c6\u7fa4\u5185\u5b9a\u4e49\u5916\u90e8\u670d\u52a1\u7684\u8d1f\u8f7d\u5747\u8861\u5730\u5740\uff0c\u63d0\u4f9b\u5bf9\u96c6\u7fa4\u5916\u90e8\u7684\u9ad8\u53ef\u7528\u548c\u8d1f\u8f7d\u5747\u8861\u8bbf\u95ee\u3002</p> </li> <li> <p>\u81ea\u5b9a\u4e49 front \u8d1f\u8f7d\u5747\u8861\u5730\u5740\u6216 backend \u8f6c\u53d1\u5730\u5740\uff0c\u4ee5\u652f\u6301\u66f4\u7075\u6d3b\u7684\u8d1f\u8f7d\u5747\u8861\u9700\u6c42\u3002</p> </li> </ol>"},{"location":"zh/usages/balancing/#_4","title":"\u7b56\u7565\u4f8b\u5b50","text":"<p>\u4ee5\u4e0b\u4f8b\u5b50\u4e2d\uff0cfront \u6307\u5b9a\u4e86 Kubernetes \u4e2d\u7684\u67d0\u4e2a service\uff0cbackend \u57fa\u4e8e pod \u7684 label selector \u8f6c\u53d1\u5230 Pod IP\u3002</p> <pre><code>apiVersion: balancing.elf.io/v1beta1\nkind: BalancingPolicy\nmetadata:\n  name: test-service-podendpoint\nspec:\n  frontend:\n    serviceMatcher:\n      serviceName: http-server-balancing-pod-v4\n      namespace: default\n      toPorts:\n        - port: \"8080\"\n          protocol: TCP\n          name: p1\n        - port: \"80\"\n          protocol: TCP\n          name: p2\n  backend:\n    serviceEndpoint:\n      endpointSelector:\n        matchLabels:\n          app: http-redirect\n      redirectMode: podEndpoint\n      toPorts:\n        - port: \"80\"\n          protocol: TCP\n          name: p1\n        - port: \"80\"\n          protocol: TCP\n          name: p2\n</code></pre> <p>\u4ee5\u4e0b\u4f8b\u5b50\u4e2d\uff0cfront \u6307\u5b9a\u4e86 Kubernetes \u4e2d\u7684\u67d0\u4e2a service\uff0cbackend \u57fa\u4e8e pod \u7684 label selector \u8f6c\u53d1\u5230 Pod \u6240\u5728\u8282\u70b9\u7684 hostPort\u3002</p> <pre><code>apiVersion: balancing.elf.io/v1beta1\nkind: BalancingPolicy\nmetadata:\n  name: test-service-hostport\nspec:\n  frontend:\n    serviceMatcher:\n      serviceName: http-server-balancing-hostport-v4\n      namespace: default\n      toPorts:\n        - port: \"80\"\n          protocol: TCP\n          name: p2\n  backend:\n    serviceEndpoint:\n      endpointSelector:\n        matchLabels:\n          app: http-redirect\n      redirectMode: hostPort\n      toPorts:\n        - port: \"20080\"\n          protocol: TCP\n          name: p2\nEOF\n</code></pre> <p>\u4ee5\u4e0b\u4f8b\u5b50\u4e2d\uff0cfront \u6307\u5b9a\u4e86 Kubernetes \u4e2d\u7684\u67d0\u4e2a service\uff0cbackend \u57fa\u4e8e pod \u7684 label selector \u8f6c\u53d1\u5230 Pod \u6240\u5728\u8282\u70b9\u7684 Proxy IP\u3002</p> <pre><code>apiVersion: balancing.elf.io/v1beta1\nkind: BalancingPolicy\nmetadata:\n  name: test-service-nodeproxy\nspec:\n  frontend:\n    serviceMatcher:\n      serviceName: http-server-balancing-nodeproxy-v4\n      namespace: default\n      toPorts:\n        - port: \"80\"\n          protocol: TCP\n          name: p2\n  backend:\n    serviceEndpoint:\n      endpointSelector:\n        matchLabels:\n          app: http-redirect\n      redirectMode: nodeProxy\n      toPorts:\n        - port: \"20080\"\n          protocol: TCP\n          name: p2\nEOF\n</code></pre> <p>\u4ee5\u4e0b\u4f8b\u5b50\u4e2d\uff0cfront \u4f7f\u7528\u4e86\u81ea\u5b9a\u4e49\u7684\u865a\u62df IP \u548c\u7aef\u53e3\uff0cbackend \u4f7f\u7528\u4e86\u81ea\u5b9a\u4e49\u7684 IP \u548c\u7aef\u53e3\u3002</p> <pre><code>apiVersion: balancing.elf.io/v1beta1\nkind: BalancingPolicy\nmetadata:\n  name: test-addr\nspec:\n  frontend:\n    addressMatcher:\n      ip: \"169.254.169.254\"\n      toPorts:\n        - port: \"8080\"\n          protocol: TCP\n          name: p1\n        - port: \"80\"\n          protocol: TCP\n          name: p2\n  backend:\n    addressEndpoint:\n      addresses:\n        - \"1.1.1.1\"\n        - \"1.1.1.2\"\n      toPorts:\n        - port: \"80\"\n          protocol: TCP\n          name: p1\n        - port: \"80\"\n          protocol: TCP\n          name: p2\n</code></pre>"},{"location":"zh/usages/install/","title":"\u5feb\u901f\u5f00\u59cb","text":""},{"location":"zh/usages/install/#_2","title":"\u5b89\u88c5\u8981\u6c42","text":"<ol> <li> <p>\u4e3b\u673a\u7684 Linux \u5185\u6838\u8981\u6c42\uff1aLinux \u5185\u6838\u7248\u672c\u6700\u597d\u5927\u4e8e v5.8\uff0c\u4ee5\u4fbf\u6240\u6709\u529f\u80fd\u90fd\u80fd\u6b63\u5e38\u8fd0\u884c\u3002</p> </li> <li> <p>\u67b6\u6784\u652f\u6301\uff1a\u5f53\u524d\u4ec5\u63d0\u4f9b AMD \u67b6\u6784\u955c\u50cf\uff0c\u5c1a\u672a\u63d0\u4f9b ARM \u67b6\u6784\u955c\u50cf\u3002</p> </li> </ol>"},{"location":"zh/usages/install/#kubernetes-balancing","title":"\u5728 Kubernetes \u96c6\u7fa4\u4e2d\u90e8\u7f72 Balancing","text":"<pre><code># \u83b7\u53d6 API Server \u7684\u8bbf\u95ee\u5730\u5740\n~# kubectl cluster-info\n  Kubernetes control plane is running at https://192.168.0.10:6443\n\n# \u90e8\u7f72 Balancing\uff0c\u9700\u5355\u72ec\u6307\u5b9a API Server \u8bbf\u95ee\u5730\u5740\uff0c\u8fd9\u6837\u5373\u4f7f\u4e0d\u8fd0\u884c kube-proxy\uff0cBalancing \u4e5f\u80fd\u8bbf\u95ee API Server \u5b8c\u6210\u5de5\u4f5c\n~# helm repo add elf https://elf-io.github.io/balancing\n~# helm install -n elf balancing elf/balancing \\\n    --set feature.apiServerHost=192.168.0.10 \\\n    --set feature.apiServerPort=6443\n\n~# kubectl get pod -n elf\n  NAME                                    READY   STATUS    RESTARTS   AGE\n  balancing-agent-jj8vq                   1/1     Running   0          4d10h\n  balancing-agent-wqs4g                   1/1     Running   0          4d10h\n  balancing-controller-849c9bd8f6-gbw6w   1/1     Running   0          4d10h\n</code></pre>"},{"location":"zh/usages/install/#balancing-agent","title":"\u5728\u96c6\u7fa4\u5916\u7684\u4e3b\u673a\u4e0a\u90e8\u7f72 Balancing Agent \u5bb9\u5668\u670d\u52a1","text":"<p>\u53ef\u4ee5\u5728\u96c6\u7fa4\u5916\u7684\u4e3b\u673a\u4e0a\u90e8\u7f72 Balancing Agent \u5bb9\u5668\u670d\u52a1\uff0c\u5176\u914d\u7f6e\u6587\u4ef6\u4e2d\u9700\u6307\u660e\u63a5\u5165\u7684 Kubernetes \u96c6\u7fa4\u914d\u7f6e\u3002</p> <pre><code>IMAGE_TAG=v0.0.2\ndocker run -d --net=host \\\n    --privileged \\\n    -e \"KUBECONFIG=/config\" \\\n    -v ./config:/config  \\\n    -v /sys/fs:/sys/fs:rw \\\n    -v /proc:/host/proc \\\n    ghcr.io/elf-io/balancing-agent:${IMAGE_TAG}\n</code></pre>"},{"location":"zh/usages/localredirect/","title":"LocalRedirect \u7b56\u7565","text":""},{"location":"zh/usages/localredirect/#_1","title":"\u4ecb\u7ecd","text":"<p>LocalRedirect \u7b56\u7565\u53c2\u8003\u4e86 cilium \u9879\u76ee\u7684\u76f8\u5173\u529f\u80fd\uff0c\u57fa\u4e8e cGroup eBPF \u6280\u672f\uff0c\u5728 Pod \u8bbf\u95ee\u6307\u5b9a\u670d\u52a1\u65f6\uff0c\u5c06\u8bf7\u6c42\u91cd\u5b9a\u5411\u5230\u540c\u8282\u70b9\u7684\u672c\u5730\u670d\u52a1\u3002</p> <p>\u5b83\u652f\u6301\u4ee5\u4e0b\u5bf9\u8c61\u7684\u8bf7\u6c42\u91cd\u5b9a\u5411\uff1a * Pod \u4e2d\u7684\u5e94\u7528 * \u96c6\u7fa4\u8282\u70b9\u4e0a\u7684\u5e94\u7528</p> <p></p>"},{"location":"zh/usages/localredirect/#_2","title":"\u529f\u80fd","text":"<p>\u5f53\u524d\u7248\u672c\u652f\u6301\u4ee5\u4e0b\u529f\u80fd\uff1a</p> <ul> <li> \u524d\u7aef\u652f\u6301\u6307\u5411\u670d\u52a1\u6216\u81ea\u5b9a\u4e49\u7684 VIP \u548c\u7aef\u53e3</li> <li> \u540e\u7aef\u652f\u6301 Pod \u6807\u7b7e\u9009\u62e9\u5668</li> <li> \u652f\u6301\u914d\u7f6e\u96c6\u7fa4\u5168\u5c40\u7684 Qos \u4e0a\u9650\u3002</li> </ul> <p>\u6ce8\u610f\uff1aBalancing Policy \u548c LocalRedirect Policy \u5b9e\u4f8b\u4e4b\u95f4\uff0c\u524d\u7aef\u4e0d\u652f\u6301\u7ed1\u5b9a\u76f8\u540c\u7684\u670d\u52a1\u6216\u5b9a\u4e49\u76f8\u540c\u7684\u865a\u62df\u5730\u5740\uff0c\u5426\u5219\u4f1a\u5bfc\u81f4\u89e3\u6790\u51b2\u7a81\u3002</p> <p>\u5f53 Balancing Policy \u6216 LocalRedirect Policy \u7684\u524d\u7aef\u4f7f\u7528\u81ea\u5b9a\u4e49 IP \u5730\u5740\u65f6\uff0c\u5982\u679c\u8be5 IP \u5730\u5740\u4e0e\u67d0\u4e2a Kubernetes \u7684\u670d\u52a1 ClusterIP \u51b2\u7a81\uff0c\u5c06\u4f18\u5148\u6309\u7167\u7b56\u7565\u7684\u8f6c\u53d1\u89c4\u5219\u8fdb\u884c\u89e3\u6790\u3002</p>"},{"location":"zh/usages/localredirect/#_3","title":"\u4f7f\u7528\u573a\u666f","text":"<ul> <li>\u4e3a Node-local DNS \u5b9e\u65bd\u900f\u660e\u91cd\u5b9a\u5411   \u4e3a\u4e86\u63d0\u9ad8 CoreDNS \u7684\u670d\u52a1\u80fd\u529b\uff0c\u907f\u514d DNS \u96ea\u5d29\u6548\u5e94\uff0c\u5f00\u6e90\u793e\u533a\u5f15\u5165\u4e86 Node-local DNS\uff0c\u5b9e\u73b0\u6bcf\u4e2a\u8282\u70b9\u7684 DNS \u7f13\u5b58\u3002</li> </ul> <p>\u4f20\u7edf\u65b9\u5f0f\u4e2d\uff0c\u901a\u8fc7\u4fee\u6539 Pod \u7684 DNS \u914d\u7f6e\u6307\u5411\u672c\u5730 Node-local DNS \u7684\u865a\u62df\u5730\u5740\uff0c\u5728\u8282\u70b9\u4e0a\u7ed1\u5b9a\u8be5\u865a\u62df\u5730\u5740\u3002\u7136\u800c\uff0c\u5f53 Node-local DNS \u6545\u969c\u6216\u5347\u7ea7\u65f6\uff0c\u8fd9\u79cd\u65b9\u5f0f\u65e0\u6cd5\u4e3a\u5e94\u7528\u63d0\u4f9b\u9ad8\u53ef\u7528\u7684 DNS \u670d\u52a1\u3002</p> <p>\u5f15\u5165 LocalRedirect \u7b56\u7565\u7684\u91cd\u5b9a\u5411\u80fd\u529b\uff0c\u65e0\u9700\u4fee\u6539 Pod \u7684 DNS \u914d\u7f6e\u6216\u5f15\u5165\u65b0\u7684\u865a\u62df\u5730\u5740\uff0c\u5373\u53ef\u4e3a Node-local DNS \u63d0\u4f9b\u900f\u660e\u3001\u9ad8\u53ef\u7528\u7684\u670d\u52a1\u91cd\u5b9a\u5411\uff0c\u652f\u6301\u5728\u672c\u5730 Node-local DNS \u6545\u969c\u6216\u5347\u7ea7\u671f\u95f4\uff0c\u5c06\u670d\u52a1\u8bbf\u95ee\u89e3\u6790\u5230\u539f\u672c\u7684 CoreDNS \u670d\u52a1\u3002</p> <p>\u53ef\u9009\u7684\uff0c\u53ef\u914d\u7f6e\u96c6\u7fa4\u5168\u5c40\u7684 Qos \u4e0a\u9650\uff0c\u5728\u6bcf\u4e00\u4e2a node \u4e0a\uff0c\u5f53\u4e3a\u67d0\u4e2a service \u7684\u91cd\u5b9a\u5411\u6b21\u6570\u8fbe\u5230\u6bcf\u79d2\u7684 QOS \u4e0a\u9650\u65f6\uff0c\u5728\u672c\u79d2\u5185\u5219\u4e0d\u4e3a\u8be5\u670d\u52a1\u5b9e\u65bd\u91cd\u5b9a\u5411\uff0c\u8ba9\u670d\u52a1\u89e3\u6790\u8d70\u6b63\u5e38\u7684\u6d41\u7a0b\u3002\u8be5\u529f\u80fd\u53ef\u7528\u4e8e\u6709\u6548\u8bbe\u7f6e\u8282\u70b9\u672c\u5730\u7684\u4ee3\u7406\u7684\u6bcf\u79d2 QOS \u4e0a\u9650\u3002</p>"},{"location":"zh/usages/localredirect/#_4","title":"\u7b56\u7565\u793a\u4f8b","text":"<p>\u4ee5\u4e0b\u662f\u4e00\u4e2a YAML \u793a\u4f8b\uff0c\u524d\u7aef\u6307\u5411\u670d\u52a1\u540d\u79f0\uff1a</p> <pre><code>apiVersion: balancing.elf.io/v1beta1\nkind: LocalRedirectPolicy\nmetadata:\n  name: test-service\nspec:\n  frontend:\n    serviceMatcher:\n      serviceName: http-server-v4\n      namespace: default\n      toPorts:\n        - port: \"8080\"\n          protocol: TCP\n          name: p1\n        - port: \"80\"\n          protocol: TCP\n          name: p2\n  backend:\n    endpointSelector:\n      matchLabels:\n        app: http-redirect\n    toPorts:\n      - port: \"80\"\n        protocol: TCP\n        name: p1\n      - port: \"80\"\n        protocol: TCP\n        name: p2\n</code></pre> <p>\u4ee5\u4e0b\u662f\u4e00\u4e2a YAML \u793a\u4f8b\uff0c\u524d\u7aef\u4f7f\u7528\u81ea\u5b9a\u4e49\u7684\u865a\u62df IP \u548c\u7aef\u53e3\uff1a</p> <pre><code>apiVersion: balancing.elf.io/v1beta1\nkind: LocalRedirectPolicy\nmetadata:\n  name: test-addr\n  annotations:\n     balancing.elf.io/serviceId: \"10091\"\nspec:\n  frontend:\n    addressMatcher:\n      ip: \"169.254.0.90\"\n      toPorts:\n        - port: \"8080\"\n          protocol: TCP\n          name: p1\n        - port: \"80\"\n          protocol: TCP\n          name: p2\n  backend:\n    endpointSelector:\n      matchLabels:\n        app: http-redirect\n    toPorts:\n      - port: \"80\"\n        protocol: TCP\n        name: p1\n      - port: \"80\"\n        protocol: TCP\n        name: p2\n</code></pre>"},{"location":"zh/usages/localredirect/#qos","title":"Qos \u9650\u6d41","text":"<p>\u5f53\u672c\u5730\u8282\u70b9\u4e3a\u67d0\u4e2a\u670d\u52a1\u5b9e\u65bd\u7684 nodelocal \u91cd\u5b9a\u5411\u8fbe\u5230\u6bcf\u79d2\u7684\u5904\u7406\u4e0a\u9650\u65f6\uff0c\u5355\u4f4d\u65f6\u95f4\u5185\u7684\u5176\u4ed6\u8bf7\u6c42\u5c06\u9000\u56de\u91c7\u7528\u5e38\u89c4\u7684 service \u89e3\u6790\u65b9\u5f0f\uff0c\u4ee5\u8f6c\u53d1\u5230\u539f\u672c\u7684\u540e\u7aef\u670d\u52a1\u3002\u8be5\u529f\u80fd\u53ef\u4e3a\u672c\u5730\u91cd\u5b9a\u5411\u4ee3\u7406\u5b9e\u65bd\u9650\u6d41\u4fdd\u62a4\u3002 </p> <ol> <li> <p>\u542f\u7528</p> <p>\u65b9\u5f0f 1\uff1a\u5728\u5b89\u88c5 balancing \u65f6\uff0c\u8bbe\u7f6e helm \u7684\u53c2\u6570 values.feature.redirectQosLimit=100</p> <p>\u65b9\u5f0f 2\uff1a\u5728\u5b89\u88c5\u5b8c\u6210 balancing \u540e\uff0c\u53ef\u8bbe\u7f6e <code>kubectl set env deployment/balancing-agent -n elf REDIRECT_QOS_LIMIT=100</code></p> </li> </ol>"},{"location":"zh/usages/service/","title":"Service \u89e3\u6790","text":""},{"location":"zh/usages/service/#_1","title":"\u4ecb\u7ecd","text":"<p>Service \u89e3\u6790\u529f\u80fd\u53c2\u8003\u4e86 Cilium \u3001Calico \u3001KPNG  \u7b49\u9879\u76ee\u7684\u76f8\u5173\u529f\u80fd\u5b9e\u73b0\uff0c\u63d0\u4f9b\u4e86 CNI \u65e0\u5173\u7684\u8d1f\u8f7d\u5747\u8861\u89e3\u6790\u6269\u5c55\u80fd\u529b\u3002</p> <p>\u5b83\u80fd\u591f\u4e3a\u4ee5\u4e0b\u5bf9\u8c61\u53d1\u9001\u7684\u8bf7\u6c42\u5b9e\u65bd\u91cd\u5b9a\u5411\u8bbf\u95ee\uff1a * Pod \u4e2d\u7684\u5e94\u7528 * \u96c6\u7fa4\u8282\u70b9\u4e0a\u7684\u5e94\u7528 * \u96c6\u7fa4\u5916\u90e8\u4e3b\u673a\u4e0a\u7684\u5e94\u7528</p>"},{"location":"zh/usages/service/#_2","title":"\u529f\u80fd","text":"<p>\u5f53\u524d\uff0c\u5b83\u5177\u5907\u5982\u4e0b\u529f\u80fd\uff1a</p> <ul> <li> \u4e3a Pod \u548c Node \u5b8c\u6210\u4e1c\u897f\u5411\u7684 Service \u89e3\u6790\uff1a\u652f\u6301\u5b83\u4eec\u4e3b\u52a8\u8bbf\u95ee ClusterIP\u3001NodePort\u3001LoadBalancer\u3001ExternalIP\uff0c\u652f\u6301\u57fa\u4e8e ClientIP \u7684 sessionAffinity\uff0c\u652f\u6301 internalTrafficPolicy \u503c\u4e3a Local\u3002</li> <li> \u4e3a\u96c6\u7fa4\u5916\u90e8\u7684\u4e3b\u673a\u5e94\u7528\uff0c\u901a\u7528\u652f\u6301 Service \u7684\u5730\u5740\u89e3\u6790\uff0c\u5305\u62ec ClusterIP\u3001NodePort\u3001LoadBalancer\u3001ExternalIP\u3002\u4f46\u662f\uff0cBalancing \u89e3\u6790\u4e3a Pod IP \u5730\u5740\uff0c\u56e0\u6b64\uff0c\u5b83\u9002\u7528\u4e8e Kubernetes \u96c6\u7fa4\u4e2d\u4f7f\u7528\u4e86\u8bf8\u5982 Macvlan \u3001Spiderpool  \u7b49 underlay CNI \u7684\u573a\u666f\uff0c\u4e5f\u9002\u7528\u4e8e\u4f7f\u7528\u4e86 BGP \u4f20\u64ad\u4e86\u96c6\u7fa4 Pod \u8def\u7531\u7684 Calico \u7b49\u573a\u666f\u3002</li> </ul> <p>\u5728\u540e\u7eed\u7248\u672c\u4e2d\uff0c\u89e3\u51b3\u5982\u4e0b\u95ee\u9898\uff1a</p> <ul> <li> \u5728 Node \u4e0a\u5b8c\u6210\u5357\u5317\u5411\u7684 Service \u89e3\u6790\uff1a\u652f\u6301\u89e3\u6790\u96c6\u7fa4\u5916\u90e8\u53d1\u9001\u7684 Service \u8bbf\u95ee\u8bf7\u6c42\uff0c\u5305\u62ec NodePort\u3001LoadBalancer\u3001ExternalIP\uff0c\u652f\u6301\u57fa\u4e8e ClientIP \u7684 sessionAffinity\uff0c\u652f\u6301 externalTrafficPolicy \u503c\u4e3a Local\u3002</li> <li> \u5bf9\u4e8e\u5b58\u91cf\u7684 sessionAffinity=ClientIP \u8f6c\u53d1\u8bb0\u5f55\uff0c\u5e94\u8be5\u9075\u5faa backend Pod \u7684\u5065\u5eb7\u72b6\u6001\uff0c\u5f53 backend Pod \u4e0d\u53ef\u7528\u65f6\uff0c\u8981\u4e2d\u65ad\u6301\u4e45\u5316\u8f6c\u53d1\u3002</li> </ul>"},{"location":"zh/usages/service/#_3","title":"\u4f7f\u7528\u573a\u666f","text":"<ul> <li> <p>\u76f8\u6bd4 iptables \u7b49\u4f20\u7edf\u6280\u672f\uff0c\u57fa\u4e8e eBPF \u6280\u672f\u5b9e\u73b0\u66f4\u52a0\u4f18\u5f02\u7684 Service \u89e3\u6790\u6027\u80fd\uff0c\u907f\u514d\u75db\u82e6\u7684 iptables \u6392\u969c\u3002</p> </li> <li> <p>\u5b83\u4e0e CNI \u65e0\u5173\uff0c\u4e3a\u8bb8\u591a\u4e0d\u5177\u5907 eBPF \u6280\u672f\u7684 CNI \u9879\u76ee\u5b8c\u6210 eBPF Service \u89e3\u6790\uff0c\u4f8b\u5982 Antrea \u3001 Kube-ovn \u3001 Flannel \u7b49\u9879\u76ee\uff0c\u4ee5\u53ca\u4e00\u4e9b\u516c\u6709\u4e91 Kubernetes \u96c6\u7fa4\u7684 Amazon VPC CNI \u3001Azure CNI \u3002\u5e76\u4e14\uff0c\u5b83\u9002\u7528\u4e8e\u8bf8\u591a underlay CNI\uff0c\u89e3\u51b3\u56e0\u4e3a\u6570\u636e\u5305\u8f6c\u53d1\u8def\u5f84\u7684\u5929\u751f\u4e0d\u80fd\u8bbf\u95ee Service \u7684\u95ee\u9898\uff0c\u4f8b\u5982 Macvlan \u3001 SR-IOV CNI \u3001 Spiderpool \u3001OVS-CNI \u3002</p> </li> </ul> <p>Cilium \u3001 Calico \u81ea\u5e26\u4e86 kube-proxy \u66ff\u4ee3\u529f\u80fd\uff0c\u4e0d\u9700\u8981\u4f7f\u7528 Balancing \u9879\u76ee\u3002</p>"}]}