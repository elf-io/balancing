{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"readme/","title":"Introduction","text":""},{"location":"readme/#what-is-balancing","title":"what is balancing","text":"<p>hello world</p>"},{"location":"develop/develop/","title":"develop","text":""},{"location":"develop/develop/#local-develop","title":"local develop","text":"<ol> <li> <p><code>make build_local_image  -e USE_PROXY_SOURCE=true</code> <code>make build_local_image  -e APT_HTTP_PROXY=http://10.64.0.3:7890</code></p> </li> <li> <p><code>make build_local_test_app_image</code></p> </li> <li></li> </ol> <pre><code>make e2e_init  -e E2E_SKIP_KUBE_PROXY=true\n</code></pre> <p>4.</p> <pre><code>make e2e_deploy\n#or\nmake e2e_deploy -e PROJECT_IMAGE_TAG=8877a79da7c0a9f159363660b5b23e5458480aea \\\n                -e TEST_APP_IMAGE_TAG=aa7693a44e205c13e9bd3bee63260c9c1048ce24\n</code></pre> <ol> <li></li> </ol> <pre><code>make e2e_test_connectivity\n\n</code></pre> <ol> <li> <p>check proscope, browser visits http://NodeIP:28000</p> </li> <li> <p>check metric</p> </li> </ol>"},{"location":"develop/ebpf/","title":"debug","text":""},{"location":"develop/ebpf/#debug-ebpf","title":"debug ebpf","text":"<pre><code>#\u4e3b\u673a\u4e0a\u7684 ebpf map\n~# ls /sys/fs/bpf/balancing/\n    map_affinity  map_backend  map_configure  map_event  map_nat_record  map_node_ip  map_node_proxy_ip  map_service\n\n#\u4e3b\u673a\u4e0a cgroup v2 \u6302\u8f7d\n~# ls /sys/fs/cgroup\n    cgroup.controllers      cgroup.stat             cpuset.cpus.isolated   dev-mqueue.mount  io.prio.class     memory.reclaim          proc-sys-fs-binfmt_misc.mount  system.slice\n    cgroup.max.depth        cgroup.subtree_control  cpuset.mems.effective  init.scope        io.stat           memory.stat             sys-fs-fuse-connections.mount  user.slice\n    cgroup.max.descendants  cgroup.threads          cpu.stat               io.cost.model     kubepods.slice    memory.zswap.writeback  sys-kernel-config.mount\n    cgroup.pressure         cpu.pressure            cpu.stat.local         io.cost.qos       memory.numa_stat  misc.capacity           sys-kernel-debug.mount\n    cgroup.procs            cpuset.cpus.effective   dev-hugepages.mount    io.pressure       memory.pressure   misc.current            sys-kernel-tracing.mount\n\n#\u67e5\u8be2\u5230\u76f8\u5173\u7684\n~# bpftool map\n\n~# bpftool prog\n\n~# bpftool cgroup tree /run/balancing/cgroupv2\n\n#\u4e3b\u673a\u65e5\u5fd7\n~#  bpftool prog tracelog\n\u6216\n~# cat /sys/kernel/debug/tracing/trace_pipe\n\n\nagent ebpf \u8bbf\u95ee\u89e3\u6790\u65e5\u5fd7\n~# kubectl logs -n elf balancing-agent-q727g | grep \"formatted ebpf event\" | jq .\n\n</code></pre>"},{"location":"develop/ebpf/#_1","title":"\u5bf9\u8c61","text":"<pre><code># \u6240\u6709\u8282\u70b9\u90fd\u6709\u552f\u4e00\u7684 annotation id\n~# kubectl get nodes -o jsonpath='{.items[*].metadata.annotations}' | jq .\n{\n  \"balancing.elf.io/nodeId\": \"596592060\",\n  \"balancing.elf.io/nodeProxyIpv4\": \"192.168.0.10\",\n  ....\n}\n\n</code></pre> <pre><code># \u6240\u6709\u7684 \u7b56\u7565\uff0c\u90fd\u6709\u4e00\u4e2a \u552f\u4e00\u7684 id\n~# kubectl get balancingpolicies -o jsonpath='{.items[*].metadata.annotations}' | jq .\n    {\n      \"balancing.elf.io/serviceId\": \"20003\",\n      ...\n    }\n\n~# kubectl get localredirectpolicies -o jsonpath='{.items[*].metadata.annotations}' | jq .\n    {\n      \"balancing.elf.io/serviceId\": \"10091\",\n      ...\n    }\n\n</code></pre>"},{"location":"develop/ebpf/#_2","title":"debug","text":"<pre><code># \u67e5\u8be2\u6307\u5b9a service \u7684 ebpf \u6570\u636e\n~# inspect  traceMapData service default redirectserver\n        trace the service data of ebpf map for the service default/redirectserver\n\n        ------------------------------\n        map Hash(map_service)#12 :\n            filterNatType service\n            filterSvcV4Id 3385136556\n\n        Service Entries:\n        [0]: key={ DestIp:172.21.197.201, DestPort:80, protocol:tcp, NatType:service, Scope:0 },\n             value={ SvcId:3385136556, TotalBackendCount:2, LocalBackendCount:1, AffinitySecond:0, NatMode:ServiceClusterIP, ServiceFlags:0, BalancingFlags:0, RedirectFlags:0 }\n        account:  1\n\n        LocalRedirect Entries:\n\n        Balancing Entries:\n\n        end map Hash(map_service)#12: account 1\n        ------------------------------\n\n\n        ------------------------------\n        map Hash(map_backend)#7 :\n            filterNatType service\n            filterSvcV4Id 3385136556\n\n        Service Entries:\n        [0]: key={ Order:0, SvcId:3385136556, port:80, protocol:tcp, NatType:service, Scope: 0 }\n             value={ PodIp:172.20.235.198 , PodPort:80, NodeId:596592060, NodePort:0 }\n        [1]: key={ Order:1, SvcId:3385136556, port:80, protocol:tcp, NatType:service, Scope: 0 }\n             value={ PodIp:172.20.254.131 , PodPort:80, NodeId:79869938, NodePort:0 }\n        account:  2\n\n\n\n        end map Hash(map_backend)#7: account 2\n        ------------------------------\n\n</code></pre>"},{"location":"usages/quick-start/","title":"Quick Start","text":""},{"location":"usages/quick-start/#kubernetes-installation","title":"kubernetes installation","text":"<pre><code># get the host address of api server\n~# kubectl cluster-info\nKubernetes control plane is running at https://192.168.0.10:6443\n\nhelm install -n elf balancing ./charts \\\n    --set feature.apiServerHost=192.168.0.10 \\\n    --set feature.apiServerPort=6443\n\n</code></pre>"},{"location":"usages/quick-start/#docker-installation-on-host","title":"docker installation on host","text":"<pre><code>  IMAGE_TAG=96abcfc96d2b33266bc62d76ee947e646267dd6e\n  docker run -d --net=host \\\n      --privileged \\\n      -e \"KUBECONFIG=/config\" \\\n      -v /tmp/config:/config  \\\n      -v /sys/fs:/sys/fs:rw \\\n      -v /proc:/host/proc \\\n      ghcr.io/elf-io/balancing-agent:${IMAGE_TAG}\n</code></pre>"}]}